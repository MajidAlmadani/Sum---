{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting paddlepaddle\n",
      "  Downloading paddlepaddle-2.6.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.6 kB)\n",
      "Collecting paddleocr\n",
      "  Downloading paddleocr-2.8.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: httpx in /opt/anaconda3/lib/python3.11/site-packages (from paddlepaddle) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.13 in /opt/anaconda3/lib/python3.11/site-packages (from paddlepaddle) (1.24.4)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/lib/python3.11/site-packages (from paddlepaddle) (10.4.0)\n",
      "Requirement already satisfied: decorator in /opt/anaconda3/lib/python3.11/site-packages (from paddlepaddle) (5.1.1)\n",
      "Collecting astor (from paddlepaddle)\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: opt-einsum==3.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from paddlepaddle) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /opt/anaconda3/lib/python3.11/site-packages (from paddlepaddle) (4.25.4)\n",
      "Requirement already satisfied: shapely in /opt/anaconda3/lib/python3.11/site-packages (from paddleocr) (2.0.6)\n",
      "Requirement already satisfied: scikit-image in /opt/anaconda3/lib/python3.11/site-packages (from paddleocr) (0.24.0)\n",
      "Requirement already satisfied: imgaug in /opt/anaconda3/lib/python3.11/site-packages (from paddleocr) (0.4.0)\n",
      "Requirement already satisfied: pyclipper in /opt/anaconda3/lib/python3.11/site-packages (from paddleocr) (1.3.0.post5)\n",
      "Requirement already satisfied: lmdb in /opt/anaconda3/lib/python3.11/site-packages (from paddleocr) (1.4.1)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.11/site-packages (from paddleocr) (4.66.5)\n",
      "Collecting rapidfuzz (from paddleocr)\n",
      "  Downloading rapidfuzz-3.10.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: opencv-python in /opt/anaconda3/lib/python3.11/site-packages (from paddleocr) (4.10.0.84)\n",
      "Collecting opencv-contrib-python (from paddleocr)\n",
      "  Downloading opencv_contrib_python-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: cython in /opt/anaconda3/lib/python3.11/site-packages (from paddleocr) (3.0.11)\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/lib/python3.11/site-packages (from paddleocr) (6.0.1)\n",
      "Collecting python-docx (from paddleocr)\n",
      "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.11/site-packages (from paddleocr) (4.12.3)\n",
      "Requirement already satisfied: fonttools>=4.24.0 in /opt/anaconda3/lib/python3.11/site-packages (from paddleocr) (4.51.0)\n",
      "Collecting fire>=0.3.0 (from paddleocr)\n",
      "  Downloading fire-0.6.0.tar.gz (88 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/anaconda3/lib/python3.11/site-packages (from paddleocr) (2.32.3)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.11/site-packages (from fire>=0.3.0->paddleocr) (1.16.0)\n",
      "Requirement already satisfied: termcolor in /opt/anaconda3/lib/python3.11/site-packages (from fire>=0.3.0->paddleocr) (2.4.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.11/site-packages (from beautifulsoup4->paddleocr) (2.5)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.11/site-packages (from httpx->paddlepaddle) (4.2.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.11/site-packages (from httpx->paddlepaddle) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.11/site-packages (from httpx->paddlepaddle) (1.0.5)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/lib/python3.11/site-packages (from httpx->paddlepaddle) (3.7)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.11/site-packages (from httpx->paddlepaddle) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx->paddlepaddle) (0.14.0)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.11/site-packages (from imgaug->paddleocr) (1.13.1)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.11/site-packages (from imgaug->paddleocr) (3.9.2)\n",
      "Requirement already satisfied: imageio in /opt/anaconda3/lib/python3.11/site-packages (from imgaug->paddleocr) (2.33.1)\n",
      "Requirement already satisfied: networkx>=2.8 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-image->paddleocr) (3.3)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-image->paddleocr) (2023.4.12)\n",
      "Requirement already satisfied: packaging>=21 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-image->paddleocr) (24.1)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-image->paddleocr) (0.4)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from python-docx->paddleocr) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in /opt/anaconda3/lib/python3.11/site-packages (from python-docx->paddleocr) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests->paddleocr) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests->paddleocr) (2.2.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->imgaug->paddleocr) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->imgaug->paddleocr) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->imgaug->paddleocr) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->imgaug->paddleocr) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->imgaug->paddleocr) (2.9.0.post0)\n",
      "Downloading paddlepaddle-2.6.2-cp311-cp311-macosx_11_0_arm64.whl (65.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading paddleocr-2.8.1-py3-none-any.whl (407 kB)\n",
      "Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Downloading opencv_contrib_python-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl (63.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "Downloading rapidfuzz-3.10.0-cp311-cp311-macosx_11_0_arm64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: fire\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fire: filename=fire-0.6.0-py2.py3-none-any.whl size=117030 sha256=154a7ff7a62bd7e816ca89897dfacddd1bc2e5199a1351c86c1519a11f8c01e4\n",
      "  Stored in directory: /Users/cornflex/Library/Caches/pip/wheels/6a/f3/0c/fa347dfa663f573462c6533d259c2c859e97e103d1ce21538f\n",
      "Successfully built fire\n",
      "Installing collected packages: rapidfuzz, python-docx, opencv-contrib-python, fire, astor, paddlepaddle, paddleocr\n",
      "Successfully installed astor-0.8.1 fire-0.6.0 opencv-contrib-python-4.10.0.84 paddleocr-2.8.1 paddlepaddle-2.6.2 python-docx-1.1.2 rapidfuzz-3.10.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install paddlepaddle paddleocr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0925 19:21:56.641599 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.642033 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.642134 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.642212 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.643707 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.644301 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.644706 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.645464 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.647061 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.647202 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.648202 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.648403 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.651295 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.651490 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.651703 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.652419 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.655311 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.655689 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.655774 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.655997 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.656625 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.656669 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.656752 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.656817 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.658052 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.658094 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.658223 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.658278 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.660151 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.660185 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.660241 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.660290 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.662343 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.662397 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.662465 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.662523 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.664395 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.664436 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.664491 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.664542 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.665117 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.665146 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.665196 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.665287 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.669251 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.669323 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.669379 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.669427 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.676956 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.677042 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.677100 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.677152 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.684697 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.684751 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.684804 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.684850 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.691830 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.691877 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.691990 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.692052 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.693760 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.693799 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.693930 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.694006 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.707609 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.707662 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.707716 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.707772 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.735440 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.735496 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.735563 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.735612 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.768007 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.768075 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.768266 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.768395 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.797837 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.797896 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.797959 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.798012 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:21:56.800267 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "100%|██████████| 69183/69183 [00:22<00:00, 3111.24it/s] \n",
      "I0925 19:22:21.573349 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.579980 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.583317 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.596061 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.596455 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.596891 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.597927 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.597949 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.597966 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.598752 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.598771 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.598788 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.599520 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.599537 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.599552 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.600896 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.600917 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.600948 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.601707 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.601732 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.601754 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.602573 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.602594 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.602622 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.603240 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.603257 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.603286 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.604524 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.605420 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.605424 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.606271 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.606295 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.606316 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.608369 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.608392 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.608413 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.608978 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.609000 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.609017 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.610342 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.610370 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.610392 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.611187 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.611215 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.611255 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.611932 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.611956 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.611972 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.612308 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.612313 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.612314 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.612315 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.612318 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.612811 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.613138 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.613727 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.613751 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.614768 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.614784 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.614800 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.614912 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.615584 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.615602 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.615617 936996864 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.618248 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.618265 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.623250 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.623255 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.623257 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.623260 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.623260 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.623385 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.623430 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.623433 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.628360 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.628368 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.628369 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.628371 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.628372 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.628991 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.628995 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.629480 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.629535 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.629539 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.634433 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.634442 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.634444 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.634446 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.634447 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.634564 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.634609 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.634611 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.639405 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.639410 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.639411 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.639413 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.639415 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.639555 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.639559 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.639667 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.639719 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.639721 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.642445 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.642450 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.642452 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.642453 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.642455 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.642514 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.642542 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.642544 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.647336 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.647346 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.647347 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.647349 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.647351 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.647423 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.647425 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.647826 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.647830 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.647830 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.647832 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.647835 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.647897 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.647899 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.647962 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.647993 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.647996 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.652518 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.652523 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.652524 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.652525 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.652526 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.652585 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.652617 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.652619 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.657251 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.657260 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.657263 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.657263 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.657265 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.657327 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.657330 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.657390 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.657428 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.657431 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.660497 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.660507 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.660509 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.660511 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.660512 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.660583 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.660607 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.660610 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.666442 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.666457 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.666460 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.666460 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.666462 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.666534 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.666538 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.666965 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.666968 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.666970 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.666971 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.666973 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.667027 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.667029 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.667073 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.667096 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.667098 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.673110 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.673118 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.673120 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.673122 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.673125 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.673179 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.673207 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.673210 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.678912 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.678918 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.678920 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.678922 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.678923 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.678977 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.678979 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.679016 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.679049 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.679051 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.686683 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.686687 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.686688 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.686690 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.686692 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.686749 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.686779 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.686782 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.702332 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.702342 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.702343 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.702344 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.702347 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.702420 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.702423 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.703307 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.703311 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.703313 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.703315 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.703316 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.703369 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.703372 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.703418 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.703440 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.703442 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.721195 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.721222 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.721225 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.721226 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.721227 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.721319 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.721359 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.721362 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.738400 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.738428 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.738431 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.738433 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.738436 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.738519 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.738523 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.738591 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.739463 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.740185 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.740501 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.740506 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.740756 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.740758 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.741165 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:22:21.741174 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "(InvalidArgument) The input of Op(Conv) should be a 4-D or 5-D Tensor. But received: input's dimension is 2, input's shape is [8, 1000].\n  [Hint: Expected in_dims.size() == 4 || in_dims.size() == 5 == true, but received in_dims.size() == 4 || in_dims.size() == 5:0 != true:1.] (at /Users/paddle/xly/workspace/293efbd7-945c-47ab-96a0-e0093f12eab2/Paddle/paddle/phi/infermeta/binary.cc:504)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 174\u001b[0m\n\u001b[1;32m    171\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m paddle\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mAdam(parameters\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters(), learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# Step 7: Train the model\u001b[39;00m\n\u001b[0;32m--> 174\u001b[0m train_model(model, dataloader, optimizer, loss_fn, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 141\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloader, optimizer, loss_fn, num_epochs)\u001b[0m\n\u001b[1;32m    138\u001b[0m labels_lengths \u001b[38;5;241m=\u001b[39m paddle\u001b[38;5;241m.\u001b[39mto_tensor([\u001b[38;5;28mlen\u001b[39m(label) \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m labels_idx], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m preds \u001b[38;5;241m=\u001b[39m model(images)  \u001b[38;5;66;03m# preds shape: [seq_len, batch_size, num_classes]\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# Prepare inputs for CTC Loss\u001b[39;00m\n\u001b[1;32m    144\u001b[0m preds \u001b[38;5;241m=\u001b[39m preds\u001b[38;5;241m.\u001b[39mlog_softmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Apply log softmax over classes\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/paddle/nn/layer/layers.py:1429\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1421\u001b[0m     (\u001b[38;5;129;01mnot\u001b[39;00m in_to_static_mode())\n\u001b[1;32m   1422\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1426\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m in_profiler_mode())\n\u001b[1;32m   1427\u001b[0m ):\n\u001b[1;32m   1428\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_once(\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1429\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dygraph_call_func(\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[0;32mIn[4], line 105\u001b[0m, in \u001b[0;36mCRNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    102\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone(x)  \u001b[38;5;66;03m# Output shape: [batch_size, 512, H, W]\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# Reduce the feature size with a convolutional layer\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(x)  \u001b[38;5;66;03m# Output shape: [batch_size, 256, H, W]\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Reshape to fit LSTM input: flatten height and channels\u001b[39;00m\n\u001b[1;32m    108\u001b[0m b, c, h, w \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/paddle/nn/layer/layers.py:1429\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1421\u001b[0m     (\u001b[38;5;129;01mnot\u001b[39;00m in_to_static_mode())\n\u001b[1;32m   1422\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1426\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m in_profiler_mode())\n\u001b[1;32m   1427\u001b[0m ):\n\u001b[1;32m   1428\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_once(\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1429\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dygraph_call_func(\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/paddle/nn/layer/conv.py:715\u001b[0m, in \u001b[0;36mConv2D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_padding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    708\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    709\u001b[0m         x,\n\u001b[1;32m    710\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice,\n\u001b[1;32m    711\u001b[0m         mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_padding_mode,\n\u001b[1;32m    712\u001b[0m         data_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_format,\n\u001b[1;32m    713\u001b[0m     )\n\u001b[0;32m--> 715\u001b[0m out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mconv\u001b[38;5;241m.\u001b[39m_conv_nd(\n\u001b[1;32m    716\u001b[0m     x,\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight,\n\u001b[1;32m    718\u001b[0m     bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    719\u001b[0m     stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stride,\n\u001b[1;32m    720\u001b[0m     padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_updated_padding,\n\u001b[1;32m    721\u001b[0m     padding_algorithm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_padding_algorithm,\n\u001b[1;32m    722\u001b[0m     dilation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dilation,\n\u001b[1;32m    723\u001b[0m     groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_groups,\n\u001b[1;32m    724\u001b[0m     data_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_format,\n\u001b[1;32m    725\u001b[0m     channel_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channel_dim,\n\u001b[1;32m    726\u001b[0m     op_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op_type,\n\u001b[1;32m    727\u001b[0m     use_cudnn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_cudnn,\n\u001b[1;32m    728\u001b[0m )\n\u001b[1;32m    729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/paddle/nn/functional/conv.py:128\u001b[0m, in \u001b[0;36m_conv_nd\u001b[0;34m(x, weight, bias, stride, padding, padding_algorithm, dilation, groups, data_format, channel_dim, op_type, use_cudnn, use_mkldnn, name)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_conv_nd\u001b[39m(\n\u001b[1;32m    111\u001b[0m     x,\n\u001b[1;32m    112\u001b[0m     weight,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    125\u001b[0m ):\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;66;03m# Due to the poor performance of NHWC, we transpose the input to NCHW.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m in_dynamic_or_pir_mode() \u001b[38;5;129;01mand\u001b[39;00m op_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv2d\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 128\u001b[0m         pre_bias \u001b[38;5;241m=\u001b[39m _C_ops\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    129\u001b[0m             x,\n\u001b[1;32m    130\u001b[0m             weight,\n\u001b[1;32m    131\u001b[0m             stride,\n\u001b[1;32m    132\u001b[0m             padding,\n\u001b[1;32m    133\u001b[0m             padding_algorithm,\n\u001b[1;32m    134\u001b[0m             dilation,\n\u001b[1;32m    135\u001b[0m             groups,\n\u001b[1;32m    136\u001b[0m             data_format,\n\u001b[1;32m    137\u001b[0m         )\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m             new_shape \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mValueError\u001b[0m: (InvalidArgument) The input of Op(Conv) should be a 4-D or 5-D Tensor. But received: input's dimension is 2, input's shape is [8, 1000].\n  [Hint: Expected in_dims.size() == 4 || in_dims.size() == 5 == true, but received in_dims.size() == 4 || in_dims.size() == 5:0 != true:1.] (at /Users/paddle/xly/workspace/293efbd7-945c-47ab-96a0-e0093f12eab2/Paddle/paddle/phi/infermeta/binary.cc:504)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "from paddle.io import Dataset, DataLoader\n",
    "from paddle.vision.transforms import Compose, Resize, ToTensor\n",
    "\n",
    "# Step 1: Define a Dataset\n",
    "class LicensePlateDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_paths = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('.png') or f.endswith('.jpg')]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        # Load the image\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # Get label from filename (assuming filename is label without extension)\n",
    "        label = os.path.splitext(os.path.basename(img_path))[0]\n",
    "        return np.array(img), label\n",
    "\n",
    "# Step 2: Define the label processing for Arabic and English\n",
    "def is_arabic_numeral(char):\n",
    "    return '\\u0660' <= char <= '\\u0669'\n",
    "\n",
    "def label_license_plate_text(recognized_text):\n",
    "    labeled_output = {\n",
    "        'English Number': '',\n",
    "        'English Letter': '',\n",
    "        'Arabic Number': '',\n",
    "        'Arabic Letter': '',\n",
    "        'Unknown': ''\n",
    "    }\n",
    "\n",
    "    for word in recognized_text.split():\n",
    "        for char in word:\n",
    "            if is_arabic_numeral(char):\n",
    "                label = 'Arabic Number'\n",
    "            elif char.isdigit():\n",
    "                label = 'English Number'\n",
    "            elif char.isalpha() and char.isascii():\n",
    "                label = 'English Letter'\n",
    "            elif char.isalpha():\n",
    "                label = 'Arabic Letter'\n",
    "            else:\n",
    "                label = 'Unknown'\n",
    "            \n",
    "            labeled_output[label] += char\n",
    "\n",
    "    return labeled_output\n",
    "\n",
    "# Define your character dictionary with Arabic and English letters/numbers\n",
    "english_chars = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'\n",
    "arabic_chars = 'ابتثجحخدذرزسشصضطظعغفقكلمنهوي' + ''.join(chr(i) for i in range(0x0660, 0x066A))  # Arabic letters + numerals\n",
    "\n",
    "# Combine Arabic and English characters\n",
    "char_dict = english_chars + arabic_chars\n",
    "num_classes = len(char_dict) + 1  # +1 for the CTC blank label\n",
    "\n",
    "# Create a mapping from characters to indices\n",
    "char_to_idx = {char: idx for idx, char in enumerate(char_dict)}\n",
    "blank_idx = num_classes - 1  # The index for the CTC blank label\n",
    "\n",
    "def encode_labels(labels):\n",
    "    labels_idx = []\n",
    "    for label in labels:\n",
    "        labeled_output = label_license_plate_text(label)  # Extract Arabic/English letters and numerals\n",
    "        label_idx = []\n",
    "        for category, text in labeled_output.items():\n",
    "            for c in text:\n",
    "                label_idx.append(char_to_idx.get(c, blank_idx))  # Map characters to indices\n",
    "        labels_idx.append(label_idx)\n",
    "    return labels_idx\n",
    "\n",
    "# Step 3: Define the CRNN Model using ResNet18 as the backbone\n",
    "class CRNN(nn.Layer):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CRNN, self).__init__()\n",
    "        \n",
    "        # Backbone: ResNet18\n",
    "        self.backbone = paddle.vision.models.resnet18(pretrained=True)\n",
    "\n",
    "        # Reduce channels and features\n",
    "        self.conv = nn.Conv2D(in_channels=512, out_channels=256, kernel_size=1)\n",
    "\n",
    "        # LSTM layer (Bidirectional)\n",
    "        self.lstm = nn.LSTM(input_size=256, hidden_size=128, num_layers=2, direction='bidirectional')\n",
    "\n",
    "        # Final fully connected layer (CTC Head)\n",
    "        self.fc = nn.Linear(128 * 2, num_classes)  # 128 * 2 because of bidirectional LSTM\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Backbone feature extraction\n",
    "        x = self.backbone(x)  # Output shape: [batch_size, 512, H, W]\n",
    "\n",
    "        # Reduce the feature size with a convolutional layer\n",
    "        x = self.conv(x)  # Output shape: [batch_size, 256, H, W]\n",
    "\n",
    "        # Reshape to fit LSTM input: flatten height and channels\n",
    "        b, c, h, w = x.shape\n",
    "        x = paddle.reshape(x, [b, c * h, w])  # Shape: [batch_size, feature_size, width]\n",
    "\n",
    "        # Transpose to match LSTM input\n",
    "        x = x.transpose([2, 0, 1])  # Shape: [width, batch_size, feature_size]\n",
    "\n",
    "        # LSTM sequence encoding\n",
    "        x, (h_n, c_n) = self.lstm(x)  # Output: [width, batch_size, hidden_size * 2]\n",
    "\n",
    "        # Reshape for the fully connected layer\n",
    "        x = paddle.reshape(x, [-1, x.shape[-1]])  # Shape: [width * batch_size, hidden_size * 2]\n",
    "\n",
    "        # Apply the fully connected layer\n",
    "        x = self.fc(x)  # Shape: [width * batch_size, num_classes]\n",
    "\n",
    "        # Reshape back to the expected shape for CTC loss\n",
    "        x = paddle.reshape(x, [-1, b, num_classes])  # Shape: [width, batch_size, num_classes]\n",
    "\n",
    "        return x\n",
    "\n",
    "# Step 4: Define the training loop\n",
    "def train_model(model, dataloader, optimizer, loss_fn, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for images, labels in dataloader:\n",
    "            images = paddle.to_tensor(images, dtype='float32')\n",
    "            labels_idx = encode_labels(labels)\n",
    "            labels_concat = [item for sublist in labels_idx for item in sublist]\n",
    "            labels_tensor = paddle.to_tensor(labels_concat, dtype='int32')\n",
    "            labels_lengths = paddle.to_tensor([len(label) for label in labels_idx], dtype='int64')\n",
    "\n",
    "            # Forward pass\n",
    "            preds = model(images)  # preds shape: [seq_len, batch_size, num_classes]\n",
    "\n",
    "            # Prepare inputs for CTC Loss\n",
    "            preds = preds.log_softmax(axis=2)  # Apply log softmax over classes\n",
    "            preds_lengths = paddle.to_tensor([preds.shape[0]] * preds.shape[1], dtype='int64')  # All sequences have the same length\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_fn(preds, labels_tensor, preds_lengths, labels_lengths)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.clear_grad()\n",
    "\n",
    "            total_loss += loss.numpy()[0]\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(dataloader):.4f}\")\n",
    "\n",
    "# Step 5: Create DataLoader\n",
    "image_dir = \"Dataset/\"  # Update this to your dataset path\n",
    "transform = Compose([\n",
    "    Resize((32, 320)),  # Resize to match the input shape\n",
    "    ToTensor()\n",
    "])\n",
    "dataset = LicensePlateDataset(image_dir, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# Step 6: Initialize model, loss function, and optimizer\n",
    "model = CRNN(num_classes)\n",
    "loss_fn = nn.CTCLoss(blank=blank_idx)  # Blank index is num_classes - 1\n",
    "optimizer = paddle.optimizer.Adam(parameters=model.parameters(), learning_rate=0.001)\n",
    "\n",
    "# Step 7: Train the model\n",
    "train_model(model, dataloader, optimizer, loss_fn, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0925 19:25:06.812199 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.814056 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.814163 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.814257 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.817037 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.817098 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.817189 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.817260 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.817907 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.818183 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.818241 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.818287 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.819173 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.819222 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.819284 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.819337 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.819939 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.819977 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.820055 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.820202 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.820523 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.820574 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.820647 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.820703 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.821733 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.821763 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.821817 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.821864 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.823712 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.823752 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.823803 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.823864 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.826731 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.826761 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.826810 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.826884 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.828716 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.828750 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.828804 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.828852 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.829607 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.829643 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.829691 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.829761 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.833269 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.833315 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.833391 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.833442 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.840073 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.840106 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.840152 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.840219 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.846846 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.846877 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.849663 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.849711 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.856603 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.856652 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.856703 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.856869 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.858788 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.858827 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.858886 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.858938 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.872442 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.872495 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.872556 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.872606 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.899209 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.899269 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.899325 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.899379 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.925824 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.925879 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.925935 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.925980 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.952586 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.952638 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.952711 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.952764 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:06.957983 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n",
      "I0925 19:25:07.587994 4172401664 kernel_dispatch.h:102] Get BackendSet from tensor\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'h' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 153\u001b[0m\n\u001b[1;32m    150\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, collate_fn\u001b[38;5;241m=\u001b[39mcustom_collate_fn)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# Step 6: Initialize model, loss function, and optimizer\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m model \u001b[38;5;241m=\u001b[39m CRNN(num_classes)\n\u001b[1;32m    154\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCTCLoss(blank\u001b[38;5;241m=\u001b[39mblank_idx)  \u001b[38;5;66;03m# Blank index is num_classes - 1\u001b[39;00m\n\u001b[1;32m    155\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m paddle\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mAdam(parameters\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters(), learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 102\u001b[0m, in \u001b[0;36mCRNN.__init__\u001b[0;34m(self, num_classes)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mConv2D(in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, out_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# LSTM layer (Bidirectional)\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLSTM(input_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m \u001b[38;5;241m*\u001b[39m h, hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, num_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbidirectional\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# Final fully connected layer (CTC Head)\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m128\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, num_classes)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'h' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "from paddle.io import Dataset, DataLoader\n",
    "from paddle.vision.transforms import Compose, Resize, ToTensor\n",
    "\n",
    "# Step 1: Define a Dataset\n",
    "class LicensePlateDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_paths = [\n",
    "            os.path.join(image_dir, f)\n",
    "            for f in os.listdir(image_dir)\n",
    "            if f.endswith('.png') or f.endswith('.jpg')\n",
    "        ]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        # Load the image\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = ToTensor()(img)\n",
    "\n",
    "        # Get label from filename (assuming filename is label without extension)\n",
    "        label = os.path.splitext(os.path.basename(img_path))[0]\n",
    "        return img, label\n",
    "\n",
    "# Step 2: Define the label processing for Arabic and English\n",
    "def is_arabic_numeral(char):\n",
    "    return '\\u0660' <= char <= '\\u0669'\n",
    "\n",
    "def label_license_plate_text(recognized_text):\n",
    "    labeled_output = {\n",
    "        'English Number': '',\n",
    "        'English Letter': '',\n",
    "        'Arabic Number': '',\n",
    "        'Arabic Letter': '',\n",
    "        'Unknown': ''\n",
    "    }\n",
    "\n",
    "    for word in recognized_text.split():\n",
    "        for char in word:\n",
    "            if is_arabic_numeral(char):\n",
    "                label = 'Arabic Number'\n",
    "            elif char.isdigit():\n",
    "                label = 'English Number'\n",
    "            elif char.isalpha() and char.isascii():\n",
    "                label = 'English Letter'\n",
    "            elif char.isalpha():\n",
    "                label = 'Arabic Letter'\n",
    "            else:\n",
    "                label = 'Unknown'\n",
    "            \n",
    "            labeled_output[label] += char\n",
    "\n",
    "    return labeled_output\n",
    "\n",
    "# Define your character dictionary with Arabic and English letters/numbers\n",
    "english_chars = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'\n",
    "arabic_chars = 'ابتثجحخدذرزسشصضطظعغفقكلمنهوي' + ''.join(chr(i) for i in range(0x0660, 0x066A))  # Arabic letters + numerals\n",
    "\n",
    "# Combine Arabic and English characters\n",
    "char_dict = english_chars + arabic_chars\n",
    "num_classes = len(char_dict) + 1  # +1 for the CTC blank label\n",
    "\n",
    "# Create a mapping from characters to indices\n",
    "char_to_idx = {char: idx for idx, char in enumerate(char_dict)}\n",
    "blank_idx = num_classes - 1  # The index for the CTC blank label\n",
    "\n",
    "def encode_labels(labels):\n",
    "    labels_idx = []\n",
    "    for label in labels:\n",
    "        labeled_output = label_license_plate_text(label)  # Extract Arabic/English letters and numerals\n",
    "        label_idx = []\n",
    "        for category, text in labeled_output.items():\n",
    "            for c in text:\n",
    "                label_idx.append(char_to_idx.get(c, blank_idx))  # Map characters to indices\n",
    "        labels_idx.append(label_idx)\n",
    "    return labels_idx\n",
    "\n",
    "# Step 3: Define the CRNN Model using ResNet18 as the backbone\n",
    "class CRNN(nn.Layer):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CRNN, self).__init__()\n",
    "        \n",
    "        # Backbone: ResNet18\n",
    "        resnet = paddle.vision.models.resnet18(pretrained=True)\n",
    "        self.feature_extractor = nn.Sequential(*list(resnet.children())[:-2])  # Remove the last pooling and FC layers\n",
    "\n",
    "        # Reduce channels and features\n",
    "        self.conv = nn.Conv2D(in_channels=512, out_channels=256, kernel_size=1)\n",
    "\n",
    "        # LSTM layer (Bidirectional)\n",
    "        self.lstm = nn.LSTM(input_size=256 * h, hidden_size=128, num_layers=2, direction='bidirectional')\n",
    "\n",
    "        # Final fully connected layer (CTC Head)\n",
    "        self.fc = nn.Linear(128 * 2, num_classes)  # 128 * 2 because of bidirectional LSTM\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Backbone feature extraction\n",
    "        x = self.feature_extractor(x)  # Output shape: [batch_size, 512, H, W]\n",
    "\n",
    "        # Reduce the feature size with a convolutional layer\n",
    "        x = self.conv(x)  # Output shape: [batch_size, 256, H, W]\n",
    "\n",
    "        # Reshape to fit LSTM input: flatten height and channels\n",
    "        b, c, h, w = x.shape\n",
    "        x = x.transpose([0, 3, 1, 2])  # [batch_size, W, C, H]\n",
    "        x = x.reshape([b, w, c * h])   # [batch_size, W, feature_size]\n",
    "\n",
    "        # Transpose to match LSTM input\n",
    "        x = x.transpose([1, 0, 2])  # Shape: [W, batch_size, feature_size]\n",
    "\n",
    "        # LSTM sequence encoding\n",
    "        x, (h_n, c_n) = self.lstm(x)  # Output: [W, batch_size, hidden_size * 2]\n",
    "\n",
    "        # Reshape for the fully connected layer\n",
    "        x = x.reshape([-1, x.shape[-1]])  # Shape: [W * batch_size, hidden_size * 2]\n",
    "\n",
    "        # Apply the fully connected layer\n",
    "        x = self.fc(x)  # Shape: [W * batch_size, num_classes]\n",
    "\n",
    "        # Reshape back to the expected shape for CTC loss\n",
    "        x = x.reshape([-1, b, num_classes])  # Shape: [W, batch_size, num_classes]\n",
    "\n",
    "        return x\n",
    "\n",
    "# Step 4: Define a custom collate function\n",
    "def custom_collate_fn(batch):\n",
    "    images = [item[0] for item in batch]\n",
    "    labels = [item[1] for item in batch]\n",
    "    images = paddle.stack(images, axis=0)\n",
    "    return images, labels\n",
    "\n",
    "# Step 5: Create DataLoader\n",
    "image_dir = \"Dataset/\"  # Update this to your dataset path\n",
    "transform = Compose([\n",
    "    Resize((32, 320)),  # Resize to match the input shape\n",
    "    ToTensor()\n",
    "])\n",
    "dataset = LicensePlateDataset(image_dir, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=custom_collate_fn)\n",
    "\n",
    "# Step 6: Initialize model, loss function, and optimizer\n",
    "model = CRNN(num_classes)\n",
    "loss_fn = nn.CTCLoss(blank=blank_idx)  # Blank index is num_classes - 1\n",
    "optimizer = paddle.optimizer.Adam(parameters=model.parameters(), learning_rate=0.001)\n",
    "\n",
    "# Step 7: Train the model\n",
    "def train_model(model, dataloader, optimizer, loss_fn, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for images, labels in dataloader:\n",
    "            images = images.astype('float32')\n",
    "            labels_idx = encode_labels(labels)\n",
    "            labels_concat = [item for sublist in labels_idx for item in sublist]\n",
    "            labels_tensor = paddle.to_tensor(labels_concat, dtype='int32')\n",
    "            labels_lengths = paddle.to_tensor([len(label) for label in labels_idx], dtype='int64')\n",
    "\n",
    "            # Forward pass\n",
    "            preds = model(images)  # preds shape: [seq_len, batch_size, num_classes]\n",
    "\n",
    "            # Prepare inputs for CTC Loss\n",
    "            preds = preds.log_softmax(axis=2)  # Apply log softmax over classes\n",
    "            preds_lengths = paddle.to_tensor([preds.shape[0]] * preds.shape[1], dtype='int64')  # All sequences have the same length\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_fn(preds, labels_tensor, preds_lengths, labels_lengths)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.clear_grad()\n",
    "\n",
    "            total_loss += loss.numpy()[0]\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(dataloader):.4f}\")\n",
    "\n",
    "train_model(model, dataloader, optimizer, loss_fn, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
